{
    "contents" : "# sentiment analysis\nrm(list = ls())\nwd <- 'C:/Users/KLN/some_r'\nsetwd(wd)\nsource('util_fun.R')\n\n###### word level lexicons/dictionaries \n# handheld with some help\nmatt.v <- paste(scan('data/kjv_books/Matthew.txt', what = 'character', sep='\\n', encoding = 'UTF-8'), collapse = \" \")\n# sentence tokenizer\nlibrary(NLP)\nlibrary(openNLP)\ntoken_sent <- function(text, lang = \"en\") {\n  sentannotator <- Maxent_Sent_Token_Annotator(language = lang)\n  text <- as.String(text)# convert to string\n  sentbound <- annotate(text, sentannotator)\n  sentences <- text[sentbound]# extract sentences\n  return(sentences)# return sentences\n}\n# sentiment function\nlexicon_scr <- function(sentences,lexicon){\n  token_word <- strsplit(tolower(sentences), \"[^A-Za-z']+\")# tokenize sentences\n  sentiment.mat = matrix()\n  for(i in 1:length(token_word)){\n    tmp <- lexicon$value[which(lexicon$word %in% token_word[[i]])]# valence\n    w <- length(tmp)# number of words\n    if (length(tmp) > 0){\n      sentiment.mat[i] <- sum(tmp)/w}\n    else{sentiment.mat[i] = 0}\n  }\n  # sentiment.mat <- TTR::SMA(sentiment.mat,n = 10)# optional smoothing\n  return(sentiment.mat)\n}\n# extract sentences\nsent.ch <- token_sent(matt.v)\nhead(sent.ch)\n# import sentiment lexicon\nafinn.dt <- read.table('AFINN-111.txt', header = FALSE, sep = '\\t',quote = \"\\\"\")\nnames(afinn.dt) <- c('word','value')\nhead(afinn.dt)\ntail(afinn.dt,10)\n# test the sentiment code\ntest.v <- c('I love whales. I hate Ahab because he is the epitome of whaling')\ntest.ch <- token_sent(test.v)\nprint(lexicon_scr(test.ch,afinn.dt))\n# run on matt\nmattsentiment.v <- lexicon_scr(sent.ch,afinn.dt)\ndev.new()\npar(mfrow = c(3,1))\nhist(mattsentiment.v)\nplot(mattsentiment.v,type = 'l', xlab = 'Narrative Time', ylab = 'Sentiment')\nplot(TTR::SMA(mattsentiment.v,60),type = 'l', xlab = 'Narrative Time', ylab = 'Sentiment')\n\n# aesthetics\nlibrary(ggplot2)\nmattsentiment.df <- data.frame(line = 1:length(mattsentiment.v), sentiment = TTR::SMA(mattsentiment.v,60))\ndev.new()\nggplot(data = mattsentiment.df, aes(x = line, y = sentiment)) +\n  geom_bar(stat = \"identity\", colour =\"#FF9999\")+\n  theme_minimal() +\n  xlab(\"Narrative Time (line)\")+\n  ylab(\"Sentiment\") +\n  labs(title = expression(paste(\"Sentiment in \", italic(\"Matthew\")))) \n\n\n### with Syuzhet library\nlibrary(syuzhet)\nlibrary(tm)\nlibrary(qdap)#qual\nls(\"package:syuzhet\")\nls(\"package:qdap\")\nhelp(package = 'qdap')\n# tokenize at sentence level\ntext_sent <- get_sentences(matt.v)\nhead(text_sent)\n# AFINN sentiment lexicon\ntext_afinn <- get_sentiment(text_sent, method = 'afinn')\n# explore\ntext_sent[which(text_afinn == max(text_afinn))]\ntext_sent[which(text_afinn == min(text_afinn))]\ntext_sent[which(text_afinn > (mean(text_afinn)+sd(text_afinn)*2))]\ntext_sent[which(text_afinn < (mean(text_afinn)-sd(text_afinn)*2))]\ndev.new()\npar(mfrow = c(2,2))\nhist(text_afinn)\nplot(text_afinn,type = 'l')\n\n#chunck text\ntext_afinn_val <- get_percentage_values(text_afinn, bin = 100)\nhist(text_afinn_val)\nplot(text_afinn_val,type = 'l')\n\n# the NRC lexicon\nmatt_nrc <- get_nrc_sentiment(text_sent)\n# several sentiment factors\nhead(matt_nrc,15)\n# explore\ntext_sent[which(matt_nrc$fear > 4)]\n\n# bit more efficient with dplyr and ggplot\nlibrary(dplyr)\nlibrary(stringr)\nprocess_sentiment <- function (atext, amethod) {\n  chunkedtext <- data_frame(x = atext) %>% \n  group_by(linenumber = ceiling(row_number() / 10)) %>% \n  summarize(text = str_c(x, collapse = \" \"))\n  mySentiment <- data.frame(cbind(linenumber = chunkedtext$linenumber, \n                                sentiment = get_sentiment(chunkedtext$text, method = amethod)))\n}\nmatt_sentiment.df <- rbind(process_sentiment(text_sent,\"afinn\") %>% mutate(method = \"AFINN\"),\n               process_sentiment(text_sent,\"bing\") %>% mutate(method = \"Bing et al\"),\n               process_sentiment(text_sent,\"nrc\") %>% mutate(method = \"NRC\"))\n\nlibrary(ggplot2)\ndev.new()\nggplot(data = matt_sentiment.df, aes(x = linenumber, y = sentiment, fill = method)) +\n  geom_bar(stat = \"identity\") + \n  facet_wrap(~method, nrow = 3) +\n  theme_minimal() +\n  ylab(\"Sentiment\") +\n  labs(title = expression(paste(\"Sentiment in \", italic(\"Matthew\")))) \n\n### sentiment as proxy for plot structure\n# fft transformation\nafinn_fft <- get_transformed_values(text_afinn)\ndev.new()\npar(mfrow = c(2,1))\nplot(text_afinn_val, type = 'l')\nplot(afinn_fft, type = 'l')\ntext_sent_100[which(afinn_fft == min(afinn_fft))]\n# discrete cosine transformation\nafinn_cos <- get_dct_transform(text_afinn)\ndev.new()\npar(mfrow = c(2,1))\nplot(text_afinn_val, type = 'l')\nplot(afinn_cos, type = 'l')\nbins = 100\ntext_sent_100 <- slice_text(text_sent,bins)\ntext_sent_100[which(afinn_cos == max(afinn_cos))]\ntext_sent_100[which(afinn_cos == min(afinn_cos))]\n# plot comparison\nbible_fft <- get_transformed_values(get_sentiment\n                                    (get_sentences(paste(scan('data/kjv.txt', \n                                                              what = 'character', sep='\\n', encoding = 'UTF-8'), collapse = \" \")),method = 'afinn'))\nkoran_fft <- get_transformed_values(get_sentiment\n                                      (get_sentences(paste(scan('data/koran.txt', \n                                                                what = 'character', sep='\\n', encoding = 'UTF-8'), collapse = \" \")),method = 'afinn'))\ndev.new()\npar(mfrow = c(2,1))\nplot(bible_fft, type = 'l', main = 'Bible, KJV' ,xlab = 'Narrative time', ylab = 'Sentiment',col = 'red',lwd = 3)\nplot(koran_fft, type = 'l', main = 'Koran, Arberry Translation', xlab = 'Narrative time', ylab = 'Sentiment',col = 'red',lwd = 3)\n#####\nlibrary(quanteda)\n\n### scaling with tm\nlibrary(tm)\ndd = \"C:/Users/KLN/some_r/data/kjv_books\";\nbooks.cor  <- Corpus(DirSource(dd, encoding = \"UTF-8\"), readerControl = list(language = \"lat\"))\nnames(books.cor) <- gsub(\"\\\\..*\",\"\",names(books.cor))# remove ending\nfilenames <- names(books.cor)\nbooks.cor <- tm_map(books.cor, PlainTextDocument)\nbooks.cor <- tm_map(books.cor, content_transformer(tolower))\nbooks.cor <- tm_map(books.cor, removePunctuation)\nbooks.cor <- tm_map(books.cor, removeNumbers)\nbooks.cor <- tm_map(books.cor, stripWhitespace)\nnames(books.cor) <- filenames\n# sentiment for each document\nafinncorpus <- function(corpus){\n  sent <- rep(0,length(corpus))\n  for(i in 1:length(corpus)){\n    sent[i] <- get_sentiment(paste(corpus[[i]]$content, collapse = \" \"),method = 'afinn')\n  }\n  return(sent)\n}\nsent.v <- afinncorpus(books.cor) \ndev.new(); barplot(sent.v, main=\"KJV sentiments\", horiz=TRUE)\n# use metadata\ntmp <- read.csv('kjv_metadata.csv',header = TRUE)\nhead(tmp)\nfor (i in 1:length(books.cor)){\n  books.cor[[i]]$meta$heading <- as.character(tmp$filename[[i]])# pre-defined tag\n  books.cor[[i]]$meta$collection <- as.character(tmp$collection[[i]])# user-defined tag\n}\nnt.cor <- books.cor[meta(books.cor, \"collection\") == 'new']# new testament\nold.cor <- books.cor[meta(books.cor, \"collection\") == 'old']# new testament\nnt.sent.v <- afinncorpus(nt.cor) \not.sent.v <- afinncorpus(old.cor)\npar(mfrow = c(1,2)); \nbarplot(nt.sent.v, main=\"KJV NT\", horiz=TRUE); abline(v = mean(nt.sent.v), col = 'red')\nbarplot(ot.sent.v, main=\"KJV OT\", horiz=TRUE); abline(v = mean(ot.sent.v), col = 'red')\n\n\n###### sentiment classifier\n## annotate sentences with with class valence and split in training and test set\n# training set\npos_sent <- rbind(c('I love text mining','positive'), c('Melville is amazing','positive'), c('I feel great today','positive'),\n                  c('I am excited about data','positive'), c('She is my best friend','positive'))\nneg_sent <- rbind(c('I do not like text mining','negative'), c('Melville is terrible','negative'), c('I feel tired today','negative'),\n                  c('I am not interested in data','negative'),c('She is my adversary','negative'))\n# test set\ntest_sent <- rbind(c('I feel love for him','positive'),c('George is my friend','positive'),c('I am not tired','positive'),\n                   c('do not like him','negative'),c('your review is terrible','negative'))\nsent <- rbind(pos_sent, neg_sent, test_sent)\nprint(sent)\nlibrary(RTextTools) # quick and dirty text classification that use tm\nlibrary(e1071) # extensive stats library for Naive Bayes algorithm\ndtm = create_matrix(sent[, 1], language = \"english\", removeStopwords = FALSE, \n                       removeNumbers = TRUE, stemWords = FALSE, tm::weightTfIdf)\ndtm.mat = as.matrix(dtm)\nsentiment.class = naiveBayes(dtm.mat[1:10, ], as.factor(sent[1:10, 2]))\npredict.f = predict(sentiment.class, dtm.mat[11:15, ])\n## diagnostics\n# confusion matrix\ntable(sent[11:15, 2], predict.f)\n# accuracy\nrecall_accuracy(sent[11:15, 2], predict.f)\n",
    "created" : 1467098215125.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3807046241",
    "id" : "75B688DD",
    "lastKnownWriteTime" : 1469697788,
    "path" : "~/courses/au_summer_university/summer_u2016/classes/tutorials/sentiments.R",
    "project_path" : "sentiments.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 15,
    "source_on_save" : false,
    "type" : "r_source"
}